{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5869783-46cd-4ef5-8d80-b1c6eaf559bd"
   },
   "source": [
    "# X·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n v√† khai ph√° d·ªØ li·ªáu vƒÉn b·∫£n\n",
    "\n",
    "![](https://www.thuatngumarketing.com/wp-content/uploads/2017/12/NLP.png.pagespeed.ce_.1YNuw_5dJH.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "372869b4-6785-4aaa-8abc-3e29d875fb0c"
   },
   "source": [
    "## ƒê·ªãnh nghƒ©a\n",
    "\n",
    "> **X·ª≠ l√≠ ng√¥n ng·ªØ t·ª± nhi√™n**: S·ª≠ d·ª•ng c√°c k·ªπ thu·∫≠t ph√¢n t√≠ch v√† l√†m s·∫°ch d·ªØ li·ªáu k·∫øt h·ª£p v·ªõi m√¥ h√¨nh h·ªçc m√°y ƒë·ªÉ khai th√°c th√¥ng tin trong d·ªØ li·ªáu ng√¥n ng·ªØ.\n",
    "\n",
    "> **D·ªØ li·ªáu ng√¥n ng·ªØ**: N√≥i cho nhau nghe (d·ªØ li·ªáu ng√¥n ng·ªØ √¢m thanh) v√† vi·∫øt cho nhau ƒë·ªçc (d·ªØ li·ªáu ng√¥n ng·ªØ vƒÉn b·∫£n)\n",
    "\n",
    "> **Text Mining**: K·ªπ thu·∫≠t x·ª≠ l√Ω d·ªØ li·ªáu d·∫°ng vƒÉn b·∫£n v√† khai th√°c th√¥ng tin t·ª´ d·ªØ li·ªáu vƒÉn b·∫£n.\n",
    "\n",
    "![](https://www.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0108.png)\n",
    "\n",
    "## ·ª®ng d·ª•ng\n",
    "\n",
    "![](https://www.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0101.png)\n",
    "\n",
    "> Tham kh·∫£o: [Practical Natural Language Processing by Sowmya Vajjala, Bodhisattwa Majumder, Anuj Gupta, Harshit Surana\n",
    "](https://www.oreilly.com/library/view/practical-natural-language/9781492054047/ch01.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "da1ff90f-7126-4e50-8272-e7bb5ebc5092"
   },
   "source": [
    "## Quy tr√¨nh\n",
    "\n",
    "> 1. **Preprocessing** (Ti·ªÅn x·ª≠ l√Ω) (L√†m s·∫°ch & Chu·∫©n ho√° d·ªØ li·ªáu)\n",
    "> 2. **Tokenizing** (T√°ch t·ª´) -> Dua ve cac cum chung\n",
    "> 3. **Vectorizing** (Vect∆° h√≥a)\n",
    "> 4. **Modeling** (X√¢y d·ª±ng m√¥ h√¨nh)\n",
    "> 5. **Intepreting result & Application** (·ª®ng d·ª•ng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4de5b914-9acd-4e9f-9072-a6663fea3313"
   },
   "source": [
    "## C√¥ng c·ª• v√† th∆∞ vi·ªán\n",
    "\n",
    "1. Python Nature Language Toolkit ([Python NLTK](https://www.nltk.org/)), PyVi h·ªó tr·ª£ x·ª≠ l√Ω d·ªØ li·ªáu d·∫°ng vƒÉn b·∫£n.\n",
    "2. Gensim/Tensorflow/Scikit-learn h·ªó tr·ª£ x√¢y d·ª±ng m√¥ h√¨nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/anaconda3/lib/python3.8/site-packages (3.5)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.8/site-packages (from nltk) (0.16.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.8/site-packages (from nltk) (4.47.0)\n",
      "Requirement already satisfied: click in /opt/anaconda3/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: regex in /opt/anaconda3/lib/python3.8/site-packages (from nltk) (2020.6.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4da8ab72-48f2-4e8d-b889-1f8637c81797"
   },
   "source": [
    "#### 1. Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu text (Text preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  h√¥m nay l√† bU·ªïi h·ªçc    cu·ªëi C·ªßa L·ªõp PY32SA3L2  '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '  h√¥m nay l√† bU·ªïi h·ªçc    \\\n",
    "cu·ªëi C·ªßa L·ªõp PY32SA3L2  '\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('H√¥m nay l√† bU·ªïi h·ªçc    cu·ªëi C·ªßa L·ªõp PY32SA3L2',\n",
       " 'H√¥m nay l√† bU·ªïi h·ªçc    cu·ªëi C·ªßa L·ªõp PY32SA3L2  ',\n",
       " '  H√¥m nay l√† bU·ªïi h·ªçc    cu·ªëi C·ªßa L·ªõp PY32SA3L2')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.strip(), text.lstrip(), text.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text = re.sub('\\s+',' ',text.strip()) # pattern_need_replace, correct_pattern, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H√¥m nay l√† bU·ªïi h·ªçc cu·ªëi C·ªßa L·ªõp PY32SA3L2'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H√îM NAY L√Ä BU·ªîI H·ªåC CU·ªêI C·ª¶A L·ªöP PY32SA3L2'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'h√¥m nay l√† bu·ªïi h·ªçc cu·ªëi c·ªßa l·ªõp py32sa3l2'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  h√¥m nay l√† bU·ªïi h·ªçc    cu·ªëi C·ªßa L·ªõp PY32SA3L2  '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  H√¥m Nay L√† Bu·ªïi H·ªçc    Cu·ªëi C·ªßa L·ªõp Py32Sa3L2  '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.strip().capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H√¥m nay l√† bu·ªïi h·ªçc cu·ªëi c·ªßa l·ªõp py32sa3l2'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H√¥m_Nay_L√†_Bu·ªïi_H·ªçc_Cu·ªëi_C·ªßa_L·ªõp_Py32Sa3L2'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.replace(\" \", \"_\").title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H√¥m_Nay_L√†_Bu·ªïi_H·ªçc_Cu·ªëi_C·ªßa_L·ªõp_Py32sa3l2'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Tach cac chu => split()\n",
    "# 2. Viet hoa chu cai dau tien cua tung chu => Capitalize()\n",
    "# 3. Join '_' vao giua cac chu da duoc viet hoa => '_'.join()\n",
    "'_'.join([x.capitalize() for x in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "651749cb-7a5f-4843-b816-67b5a34effde"
   },
   "source": [
    "#### TODO: L√†m s·∫°ch d·ªØ li·ªáu ch·ªâ gi·ªØ l·∫°i d·ªØ li·ªáu b·∫±ng ch·ªØ\n",
    "1. N·∫øu l√† d·ªØ li·ªáu scrapped t·ª´ web th√¨ ch·ªâ tr√≠ch l·ªçc d·ªØ li·ªáu chu (text only)\n",
    "2. Lo·∫°i b·ªè hyperlink (n·∫øu c√≥) # https://baophapluat.com # l·∫´n th√†nh t·ª´ word \n",
    "3. N·∫øu l√† d·ªØ li·ªáu web th√¨ c·∫ßn lo·∫°i b·ªè emoji # :smile: :angry:\n",
    "4. Lo·∫°i b·ªè t·∫•t c·∫£ c√°c d·∫•u (.,\\/!@#$%^&*()+_ etc.)\n",
    "```\n",
    "r'[\\,\\.\\/\\\\\\!\\@\\#\\+\\\"\\'\\;\\)\\(\\‚Äú\\‚Äù\\\\\\-\\:‚Ä¶&><=\\-\\%\\|\\^\\$\\&\\)\\(\\[\\]\\{\\}\\?\\*\\‚Ä¢]'\n",
    "```\n",
    "5. Lo·∫°i b·ªè t·∫•t c·∫£ c√°c s·ªë\n",
    "6. Lo·∫°i b·ªè c√°c kho·∫£ng tr·∫Øng v√† ƒë·ªïi text th√†nh lowercase # normalize # T == t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''<head></head>\n",
    "<body>\n",
    "    <p>\n",
    "    Here's 1 paragraph of text üî•. !\n",
    "    <a href=\"https://www.dataquest.io\">Learn Data Science Online ü§°</a>\n",
    "    </p>\n",
    "    <p>\n",
    "    Here's a 2nd paragraph of text! Further informations at http://mci.com.vn\n",
    "    <a href=\"https://www.python.org\">Python 101</a> </p>\n",
    "</body></html>'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<head></head>\\n<body>\\n    <p>\\n    Here\\'s 1 paragraph of text üî•. !\\n    <a href=\"https://www.dataquest.io\">Learn Data Science Online ü§°</a>\\n    </p>\\n    <p>\\n    Here\\'s a 2nd paragraph of text! Further informations at http://mci.com.vn\\n    <a href=\"https://www.python.org\">Python 101</a> </p>\\n</body></html>'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in /opt/anaconda3/lib/python3.8/site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.8/site-packages (from bs4) (4.9.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.8/site-packages (from beautifulsoup4->bs4) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "def del_html(text):\n",
    "    soup = bs4.BeautifulSoup(text).get_text(' ')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n \\n \\n    Here's 1 paragraph of text üî•. !\\n     Learn Data Science Online ü§° \\n \\n \\n    Here's a 2nd paragraph of text! Further informations at http://mci.com.vn\\n     Python 101   \\n\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = del_html(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def del_link(text):\n",
    "    link = 'http[\\S]*'\n",
    "    text = re.sub(link, ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n \\n \\n    Here's 1 paragraph of text üî•. !\\n     Learn Data Science Online ü§° \\n \\n \\n    Here's a 2nd paragraph of text! Further informations at  \\n     Python 101   \\n\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = del_link(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: demoji in /opt/anaconda3/lib/python3.8/site-packages (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install demoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import demoji\n",
    "def del_emoji(text):\n",
    "    return demoji.replace(text, ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n \\n \\n    Here's 1 paragraph of text  . !\\n     Learn Data Science Online   \\n \\n \\n    Here's a 2nd paragraph of text! Further informations at  \\n     Python 101   \\n\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = del_emoji(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_punctuation(text):\n",
    "    pattern = r'[\\,\\.\\/\\\\\\!\\@\\#\\+\\\"\\'\\;\\)\\(\\‚Äú\\‚Äù\\\\\\-\\:‚Ä¶&><=\\-\\%\\|\\^\\$\\&\\)\\(\\[\\]\\{\\}\\?\\*\\‚Ä¢]'\n",
    "    record = re.sub(pattern, ' ', text)\n",
    "    return re.sub(r'\\n', ' ', record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'         Here s 1 paragraph of text           Learn Data Science Online            Here s a 2nd paragraph of text  Further informations at        Python 101    '"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = del_punctuation(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_number(text):\n",
    "    pattern = r'\\d'\n",
    "    return re.sub(pattern, ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'         Here s   paragraph of text           Learn Data Science Online            Here s a  nd paragraph of text  Further informations at        Python        '"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = del_number(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_space(text):\n",
    "    pattern = r'\\s+'\n",
    "    return re.sub(pattern, ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Here s paragraph of text Learn Data Science Online Here s a nd paragraph of text Further informations at Python '"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = del_space(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = del_html(text)\n",
    "    text = del_link(text)\n",
    "    text = del_emoji(text)\n",
    "    text = del_punctuation(text)\n",
    "    text = del_number(text)\n",
    "    text = del_space(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. T√°ch t·ª´ (Tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into character -> vocab\n",
    "# split into word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 't', ' ', 'w', 'a', 's']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_char(text):\n",
    "    return [char for char in text]\n",
    "split_char('It was')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"It's\", 'the', 'best', 'of', 'time']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'It\\'s the best of time'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/hieu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Here',\n",
       " 's',\n",
       " 'paragraph',\n",
       " 'of',\n",
       " 'text',\n",
       " 'Learn',\n",
       " 'Data',\n",
       " 'Science',\n",
       " 'Online',\n",
       " 'Here',\n",
       " 's',\n",
       " 'a',\n",
       " 'nd',\n",
       " 'paragraph',\n",
       " 'of',\n",
       " 'text',\n",
       " 'Further',\n",
       " 'informations',\n",
       " 'at',\n",
       " 'Python']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Today is the last lesson.', 'Wish you all the best!']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.sent_tokenize('Today is the last lesson. Wish you all the best!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyvi in /opt/anaconda3/lib/python3.8/site-packages (0.1.1)\n",
      "Requirement already satisfied: sklearn-crfsuite in /opt/anaconda3/lib/python3.8/site-packages (from pyvi) (0.3.6)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.8/site-packages (from pyvi) (0.23.1)\n",
      "Requirement already satisfied: tqdm>=2.0 in /opt/anaconda3/lib/python3.8/site-packages (from sklearn-crfsuite->pyvi) (4.47.0)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.8/site-packages (from sklearn-crfsuite->pyvi) (1.15.0)\n",
      "Requirement already satisfied: tabulate in /opt/anaconda3/lib/python3.8/site-packages (from sklearn-crfsuite->pyvi) (0.8.9)\n",
      "Requirement already satisfied: python-crfsuite>=0.8.3 in /opt/anaconda3/lib/python3.8/site-packages (from sklearn-crfsuite->pyvi) (0.9.8)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->pyvi) (1.18.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->pyvi) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->pyvi) (0.16.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/anaconda3/lib/python3.8/site-packages (from scikit-learn->pyvi) (1.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvi.ViTokenizer import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ha_Noi nghin nam van hien'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Ha Noi nghin nam van hien'\n",
    "tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hoc sinh hoc sinh hoc'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'hoc sinh hoc sinh hoc'\n",
    "tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aa513f1e-0125-4cdc-a268-883af940025b"
   },
   "source": [
    "#### 3. M√£ h√≥a d·ªØ li·ªáu text (Word embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>snippet</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Th·ªß t∆∞·ªõng: Kh√°c v·ªõi ƒëa s·ªë c√°c n∆∞·ªõc, d∆∞ ƒë·ªãa ch√≠...</td>\n",
       "      <td>(T·ªï Qu·ªëc) - V·ªõi b·ªëi c·∫£nh hi·ªán nay, H·ªôi ƒë·ªìng T∆∞...</td>\n",
       "      <td>S√°ng ng√†y 9/7, H·ªôi ƒë·ªìng T∆∞ v·∫•n ch√≠nh s√°ch t√†i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Th·ªëng nh·∫•t k·ªãch b·∫£n tƒÉng tr∆∞·ªüng 3-4%, l·∫°m ph√°t...</td>\n",
       "      <td>T·∫°i cu·ªôc h·ªçp H·ªôi ƒë·ªìng T∆∞ v·∫•n ch√≠nh s√°ch t√†i ch...</td>\n",
       "      <td>Tham d·ª± cu·ªôc h·ªçp c√≥ Th·ªëng ƒë·ªëc NHNN L√™ Minh H∆∞n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ƒê·ªÅ xu·∫•t tƒÉng li·ªÅu l∆∞·ª£ng g√≥i k√≠ch th√≠ch kinh t·∫ø...</td>\n",
       "      <td>Chuy√™n gia ƒë·ªÅ xu·∫•t do d·ªãch b·ªánh Covid-19 c√≤n k...</td>\n",
       "      <td>S√°ng 9/7, Th·ªß t∆∞·ªõng Nguy·ªÖn Xu√¢n Ph√∫c ch·ªß tr√¨ h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Th·ªß t∆∞·ªõng: Kh√°c v·ªõi ƒëa s·ªë c√°c n∆∞·ªõc, d∆∞ ƒë·ªãa ch√≠...</td>\n",
       "      <td>V·ªõi b·ªëi c·∫£nh hi·ªán nay, H·ªôi ƒë·ªìng T∆∞ v·∫•n ch√≠nh s...</td>\n",
       "      <td>V·ªõi b·ªëi c·∫£nh hi·ªán nay, H·ªôi ƒë·ªìng T∆∞ v·∫•n ch√≠nh s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T√°c ƒë·ªông t·ª´ ch√≠nh s√°ch t√≠n d·ª•ng: BƒêS c√≥ th·ªÉ ƒë√≥...</td>\n",
       "      <td>ƒê·ªông th√°i th·∫Øt ch·∫∑t hay n·ªõi l·ªèng c·ªßa ch√≠nh s√°c...</td>\n",
       "      <td>L·ªùi t√≤a so·∫°n Th·ªã tr∆∞·ªùng b·∫•t ƒë·ªông s·∫£n ng√†y c√†ng...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Th·ªß t∆∞·ªõng: Kh√°c v·ªõi ƒëa s·ªë c√°c n∆∞·ªõc, d∆∞ ƒë·ªãa ch√≠...   \n",
       "1  Th·ªëng nh·∫•t k·ªãch b·∫£n tƒÉng tr∆∞·ªüng 3-4%, l·∫°m ph√°t...   \n",
       "2  ƒê·ªÅ xu·∫•t tƒÉng li·ªÅu l∆∞·ª£ng g√≥i k√≠ch th√≠ch kinh t·∫ø...   \n",
       "3  Th·ªß t∆∞·ªõng: Kh√°c v·ªõi ƒëa s·ªë c√°c n∆∞·ªõc, d∆∞ ƒë·ªãa ch√≠...   \n",
       "4  T√°c ƒë·ªông t·ª´ ch√≠nh s√°ch t√≠n d·ª•ng: BƒêS c√≥ th·ªÉ ƒë√≥...   \n",
       "\n",
       "                                             snippet  \\\n",
       "0  (T·ªï Qu·ªëc) - V·ªõi b·ªëi c·∫£nh hi·ªán nay, H·ªôi ƒë·ªìng T∆∞...   \n",
       "1  T·∫°i cu·ªôc h·ªçp H·ªôi ƒë·ªìng T∆∞ v·∫•n ch√≠nh s√°ch t√†i ch...   \n",
       "2  Chuy√™n gia ƒë·ªÅ xu·∫•t do d·ªãch b·ªánh Covid-19 c√≤n k...   \n",
       "3  V·ªõi b·ªëi c·∫£nh hi·ªán nay, H·ªôi ƒë·ªìng T∆∞ v·∫•n ch√≠nh s...   \n",
       "4  ƒê·ªông th√°i th·∫Øt ch·∫∑t hay n·ªõi l·ªèng c·ªßa ch√≠nh s√°c...   \n",
       "\n",
       "                                             content  \n",
       "0  S√°ng ng√†y 9/7, H·ªôi ƒë·ªìng T∆∞ v·∫•n ch√≠nh s√°ch t√†i ...  \n",
       "1  Tham d·ª± cu·ªôc h·ªçp c√≥ Th·ªëng ƒë·ªëc NHNN L√™ Minh H∆∞n...  \n",
       "2  S√°ng 9/7, Th·ªß t∆∞·ªõng Nguy·ªÖn Xu√¢n Ph√∫c ch·ªß tr√¨ h...  \n",
       "3  V·ªõi b·ªëi c·∫£nh hi·ªán nay, H·ªôi ƒë·ªìng T∆∞ v·∫•n ch√≠nh s...  \n",
       "4  L·ªùi t√≤a so·∫°n Th·ªã tr∆∞·ªùng b·∫•t ƒë·ªông s·∫£n ng√†y c√†ng...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json('data.json')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = del_html(text)\n",
    "    text = del_link(text)\n",
    "    text = del_emoji(text)\n",
    "    text = del_punctuation(text)\n",
    "    text = del_number(text)\n",
    "    text = del_space(text)\n",
    "    return tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Th·ªß_t∆∞·ªõng Kh√°c v·ªõi ƒëa_s·ªë c√°c n∆∞·ªõc d∆∞ ƒë·ªãa_ch√≠nh...\n",
       "1          Th·ªëng_nh·∫•t k·ªãch_b·∫£n tƒÉng_tr∆∞·ªüng l·∫°m_ph√°t d∆∞·ªõi\n",
       "2      ƒê·ªÅ_xu·∫•t tƒÉng li·ªÅu_l∆∞·ª£ng g√≥i k√≠ch_th√≠ch kinh_t·∫ø...\n",
       "3      Th·ªß_t∆∞·ªõng Kh√°c v·ªõi ƒëa_s·ªë c√°c n∆∞·ªõc d∆∞ ƒë·ªãa_ch√≠nh...\n",
       "4      T√°c_ƒë·ªông t·ª´ ch√≠nh_s√°ch t√≠n_d·ª•ng BƒêS c√≥_th·ªÉ ƒë√≥n...\n",
       "                             ...                        \n",
       "871    Vi·ªát_Nam th√†nh_l·∫≠p Vi·ªán nghi√™n_c·ª©u ph√°t_tri·ªÉn ...\n",
       "872                         B·∫•t_ƒë·ªông_s·∫£n ch·ªù l·ª±c b·∫≠t m·ªõi\n",
       "873    Di·ªÖn_ƒë√†n B·∫•t_ƒë·ªông_s·∫£n C∆°_h·ªôi m·ªõi t·ª´ ch√≠nh_s√°ch...\n",
       "874    Th·ªëng_ƒë·ªëc L√™_Minh_H∆∞ng_T√≠n_d·ª•ng tƒÉng tr·ªü_l·∫°i n...\n",
       "875    S·∫µn_s√†ng ƒë√≥n_nh·∫≠n d√≤ng v·ªën ƒë·∫ßu_t∆∞ d·ªãch_chuy·ªÉn ...\n",
       "Name: title, Length: 876, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>snippet</th>\n",
       "      <th>content</th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Th·ªß t∆∞·ªõng: Kh√°c v·ªõi ƒëa s·ªë c√°c n∆∞·ªõc, d∆∞ ƒë·ªãa ch√≠...</td>\n",
       "      <td>(T·ªï Qu·ªëc) - V·ªõi b·ªëi c·∫£nh hi·ªán nay, H·ªôi ƒë·ªìng T∆∞...</td>\n",
       "      <td>S√°ng ng√†y 9/7, H·ªôi ƒë·ªìng T∆∞ v·∫•n ch√≠nh s√°ch t√†i ...</td>\n",
       "      <td>Th·ªß t∆∞·ªõng: Kh√°c v·ªõi ƒëa s·ªë c√°c n∆∞·ªõc, d∆∞ ƒë·ªãa ch√≠...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Th·ªëng nh·∫•t k·ªãch b·∫£n tƒÉng tr∆∞·ªüng 3-4%, l·∫°m ph√°t...</td>\n",
       "      <td>T·∫°i cu·ªôc h·ªçp H·ªôi ƒë·ªìng T∆∞ v·∫•n ch√≠nh s√°ch t√†i ch...</td>\n",
       "      <td>Tham d·ª± cu·ªôc h·ªçp c√≥ Th·ªëng ƒë·ªëc NHNN L√™ Minh H∆∞n...</td>\n",
       "      <td>Th·ªëng nh·∫•t k·ªãch b·∫£n tƒÉng tr∆∞·ªüng 3-4%, l·∫°m ph√°t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ƒê·ªÅ xu·∫•t tƒÉng li·ªÅu l∆∞·ª£ng g√≥i k√≠ch th√≠ch kinh t·∫ø...</td>\n",
       "      <td>Chuy√™n gia ƒë·ªÅ xu·∫•t do d·ªãch b·ªánh Covid-19 c√≤n k...</td>\n",
       "      <td>S√°ng 9/7, Th·ªß t∆∞·ªõng Nguy·ªÖn Xu√¢n Ph√∫c ch·ªß tr√¨ h...</td>\n",
       "      <td>ƒê·ªÅ xu·∫•t tƒÉng li·ªÅu l∆∞·ª£ng g√≥i k√≠ch th√≠ch kinh t·∫ø...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Th·ªß t∆∞·ªõng: Kh√°c v·ªõi ƒëa s·ªë c√°c n∆∞·ªõc, d∆∞ ƒë·ªãa ch√≠...</td>\n",
       "      <td>V·ªõi b·ªëi c·∫£nh hi·ªán nay, H·ªôi ƒë·ªìng T∆∞ v·∫•n ch√≠nh s...</td>\n",
       "      <td>V·ªõi b·ªëi c·∫£nh hi·ªán nay, H·ªôi ƒë·ªìng T∆∞ v·∫•n ch√≠nh s...</td>\n",
       "      <td>Th·ªß t∆∞·ªõng: Kh√°c v·ªõi ƒëa s·ªë c√°c n∆∞·ªõc, d∆∞ ƒë·ªãa ch√≠...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T√°c ƒë·ªông t·ª´ ch√≠nh s√°ch t√≠n d·ª•ng: BƒêS c√≥ th·ªÉ ƒë√≥...</td>\n",
       "      <td>ƒê·ªông th√°i th·∫Øt ch·∫∑t hay n·ªõi l·ªèng c·ªßa ch√≠nh s√°c...</td>\n",
       "      <td>L·ªùi t√≤a so·∫°n Th·ªã tr∆∞·ªùng b·∫•t ƒë·ªông s·∫£n ng√†y c√†ng...</td>\n",
       "      <td>T√°c ƒë·ªông t·ª´ ch√≠nh s√°ch t√≠n d·ª•ng: BƒêS c√≥ th·ªÉ ƒë√≥...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Th·ªß t∆∞·ªõng: Kh√°c v·ªõi ƒëa s·ªë c√°c n∆∞·ªõc, d∆∞ ƒë·ªãa ch√≠...   \n",
       "1  Th·ªëng nh·∫•t k·ªãch b·∫£n tƒÉng tr∆∞·ªüng 3-4%, l·∫°m ph√°t...   \n",
       "2  ƒê·ªÅ xu·∫•t tƒÉng li·ªÅu l∆∞·ª£ng g√≥i k√≠ch th√≠ch kinh t·∫ø...   \n",
       "3  Th·ªß t∆∞·ªõng: Kh√°c v·ªõi ƒëa s·ªë c√°c n∆∞·ªõc, d∆∞ ƒë·ªãa ch√≠...   \n",
       "4  T√°c ƒë·ªông t·ª´ ch√≠nh s√°ch t√≠n d·ª•ng: BƒêS c√≥ th·ªÉ ƒë√≥...   \n",
       "\n",
       "                                             snippet  \\\n",
       "0  (T·ªï Qu·ªëc) - V·ªõi b·ªëi c·∫£nh hi·ªán nay, H·ªôi ƒë·ªìng T∆∞...   \n",
       "1  T·∫°i cu·ªôc h·ªçp H·ªôi ƒë·ªìng T∆∞ v·∫•n ch√≠nh s√°ch t√†i ch...   \n",
       "2  Chuy√™n gia ƒë·ªÅ xu·∫•t do d·ªãch b·ªánh Covid-19 c√≤n k...   \n",
       "3  V·ªõi b·ªëi c·∫£nh hi·ªán nay, H·ªôi ƒë·ªìng T∆∞ v·∫•n ch√≠nh s...   \n",
       "4  ƒê·ªông th√°i th·∫Øt ch·∫∑t hay n·ªõi l·ªèng c·ªßa ch√≠nh s√°c...   \n",
       "\n",
       "                                             content  \\\n",
       "0  S√°ng ng√†y 9/7, H·ªôi ƒë·ªìng T∆∞ v·∫•n ch√≠nh s√°ch t√†i ...   \n",
       "1  Tham d·ª± cu·ªôc h·ªçp c√≥ Th·ªëng ƒë·ªëc NHNN L√™ Minh H∆∞n...   \n",
       "2  S√°ng 9/7, Th·ªß t∆∞·ªõng Nguy·ªÖn Xu√¢n Ph√∫c ch·ªß tr√¨ h...   \n",
       "3  V·ªõi b·ªëi c·∫£nh hi·ªán nay, H·ªôi ƒë·ªìng T∆∞ v·∫•n ch√≠nh s...   \n",
       "4  L·ªùi t√≤a so·∫°n Th·ªã tr∆∞·ªùng b·∫•t ƒë·ªông s·∫£n ng√†y c√†ng...   \n",
       "\n",
       "                                              corpus  \n",
       "0  Th·ªß t∆∞·ªõng: Kh√°c v·ªõi ƒëa s·ªë c√°c n∆∞·ªõc, d∆∞ ƒë·ªãa ch√≠...  \n",
       "1  Th·ªëng nh·∫•t k·ªãch b·∫£n tƒÉng tr∆∞·ªüng 3-4%, l·∫°m ph√°t...  \n",
       "2  ƒê·ªÅ xu·∫•t tƒÉng li·ªÅu l∆∞·ª£ng g√≥i k√≠ch th√≠ch kinh t·∫ø...  \n",
       "3  Th·ªß t∆∞·ªõng: Kh√°c v·ªõi ƒëa s·ªë c√°c n∆∞·ªõc, d∆∞ ƒë·ªãa ch√≠...  \n",
       "4  T√°c ƒë·ªông t·ª´ ch√≠nh s√°ch t√≠n d·ª•ng: BƒêS c√≥ th·ªÉ ƒë√≥...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['corpus'] = df.apply(lambda x: ' '.join(x),axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>snippet</th>\n",
       "      <th>content</th>\n",
       "      <th>corpus</th>\n",
       "      <th>clean_corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Th·ªß t∆∞·ªõng: Kh√°c v·ªõi ƒëa s·ªë c√°c n∆∞·ªõc, d∆∞ ƒë·ªãa ch√≠...</td>\n",
       "      <td>(T·ªï Qu·ªëc) - V·ªõi b·ªëi c·∫£nh hi·ªán nay, H·ªôi ƒë·ªìng T∆∞...</td>\n",
       "      <td>S√°ng ng√†y 9/7, H·ªôi ƒë·ªìng T∆∞ v·∫•n ch√≠nh s√°ch t√†i ...</td>\n",
       "      <td>Th·ªß t∆∞·ªõng: Kh√°c v·ªõi ƒëa s·ªë c√°c n∆∞·ªõc, d∆∞ ƒë·ªãa ch√≠...</td>\n",
       "      <td>Th·ªß_t∆∞·ªõng Kh√°c v·ªõi ƒëa_s·ªë c√°c n∆∞·ªõc d∆∞ ƒë·ªãa_ch√≠nh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Th·ªëng nh·∫•t k·ªãch b·∫£n tƒÉng tr∆∞·ªüng 3-4%, l·∫°m ph√°t...</td>\n",
       "      <td>T·∫°i cu·ªôc h·ªçp H·ªôi ƒë·ªìng T∆∞ v·∫•n ch√≠nh s√°ch t√†i ch...</td>\n",
       "      <td>Tham d·ª± cu·ªôc h·ªçp c√≥ Th·ªëng ƒë·ªëc NHNN L√™ Minh H∆∞n...</td>\n",
       "      <td>Th·ªëng nh·∫•t k·ªãch b·∫£n tƒÉng tr∆∞·ªüng 3-4%, l·∫°m ph√°t...</td>\n",
       "      <td>Th·ªëng_nh·∫•t k·ªãch_b·∫£n tƒÉng_tr∆∞·ªüng l·∫°m_ph√°t d∆∞·ªõi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ƒê·ªÅ xu·∫•t tƒÉng li·ªÅu l∆∞·ª£ng g√≥i k√≠ch th√≠ch kinh t·∫ø...</td>\n",
       "      <td>Chuy√™n gia ƒë·ªÅ xu·∫•t do d·ªãch b·ªánh Covid-19 c√≤n k...</td>\n",
       "      <td>S√°ng 9/7, Th·ªß t∆∞·ªõng Nguy·ªÖn Xu√¢n Ph√∫c ch·ªß tr√¨ h...</td>\n",
       "      <td>ƒê·ªÅ xu·∫•t tƒÉng li·ªÅu l∆∞·ª£ng g√≥i k√≠ch th√≠ch kinh t·∫ø...</td>\n",
       "      <td>ƒê·ªÅ_xu·∫•t tƒÉng li·ªÅu_l∆∞·ª£ng g√≥i k√≠ch_th√≠ch kinh_t·∫ø...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Th·ªß t∆∞·ªõng: Kh√°c v·ªõi ƒëa s·ªë c√°c n∆∞·ªõc, d∆∞ ƒë·ªãa ch√≠...</td>\n",
       "      <td>V·ªõi b·ªëi c·∫£nh hi·ªán nay, H·ªôi ƒë·ªìng T∆∞ v·∫•n ch√≠nh s...</td>\n",
       "      <td>V·ªõi b·ªëi c·∫£nh hi·ªán nay, H·ªôi ƒë·ªìng T∆∞ v·∫•n ch√≠nh s...</td>\n",
       "      <td>Th·ªß t∆∞·ªõng: Kh√°c v·ªõi ƒëa s·ªë c√°c n∆∞·ªõc, d∆∞ ƒë·ªãa ch√≠...</td>\n",
       "      <td>Th·ªß_t∆∞·ªõng Kh√°c v·ªõi ƒëa_s·ªë c√°c n∆∞·ªõc d∆∞ ƒë·ªãa_ch√≠nh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T√°c ƒë·ªông t·ª´ ch√≠nh s√°ch t√≠n d·ª•ng: BƒêS c√≥ th·ªÉ ƒë√≥...</td>\n",
       "      <td>ƒê·ªông th√°i th·∫Øt ch·∫∑t hay n·ªõi l·ªèng c·ªßa ch√≠nh s√°c...</td>\n",
       "      <td>L·ªùi t√≤a so·∫°n Th·ªã tr∆∞·ªùng b·∫•t ƒë·ªông s·∫£n ng√†y c√†ng...</td>\n",
       "      <td>T√°c ƒë·ªông t·ª´ ch√≠nh s√°ch t√≠n d·ª•ng: BƒêS c√≥ th·ªÉ ƒë√≥...</td>\n",
       "      <td>T√°c_ƒë·ªông t·ª´ ch√≠nh_s√°ch t√≠n_d·ª•ng BƒêS c√≥_th·ªÉ ƒë√≥n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Th·ªß t∆∞·ªõng: Kh√°c v·ªõi ƒëa s·ªë c√°c n∆∞·ªõc, d∆∞ ƒë·ªãa ch√≠...   \n",
       "1  Th·ªëng nh·∫•t k·ªãch b·∫£n tƒÉng tr∆∞·ªüng 3-4%, l·∫°m ph√°t...   \n",
       "2  ƒê·ªÅ xu·∫•t tƒÉng li·ªÅu l∆∞·ª£ng g√≥i k√≠ch th√≠ch kinh t·∫ø...   \n",
       "3  Th·ªß t∆∞·ªõng: Kh√°c v·ªõi ƒëa s·ªë c√°c n∆∞·ªõc, d∆∞ ƒë·ªãa ch√≠...   \n",
       "4  T√°c ƒë·ªông t·ª´ ch√≠nh s√°ch t√≠n d·ª•ng: BƒêS c√≥ th·ªÉ ƒë√≥...   \n",
       "\n",
       "                                             snippet  \\\n",
       "0  (T·ªï Qu·ªëc) - V·ªõi b·ªëi c·∫£nh hi·ªán nay, H·ªôi ƒë·ªìng T∆∞...   \n",
       "1  T·∫°i cu·ªôc h·ªçp H·ªôi ƒë·ªìng T∆∞ v·∫•n ch√≠nh s√°ch t√†i ch...   \n",
       "2  Chuy√™n gia ƒë·ªÅ xu·∫•t do d·ªãch b·ªánh Covid-19 c√≤n k...   \n",
       "3  V·ªõi b·ªëi c·∫£nh hi·ªán nay, H·ªôi ƒë·ªìng T∆∞ v·∫•n ch√≠nh s...   \n",
       "4  ƒê·ªông th√°i th·∫Øt ch·∫∑t hay n·ªõi l·ªèng c·ªßa ch√≠nh s√°c...   \n",
       "\n",
       "                                             content  \\\n",
       "0  S√°ng ng√†y 9/7, H·ªôi ƒë·ªìng T∆∞ v·∫•n ch√≠nh s√°ch t√†i ...   \n",
       "1  Tham d·ª± cu·ªôc h·ªçp c√≥ Th·ªëng ƒë·ªëc NHNN L√™ Minh H∆∞n...   \n",
       "2  S√°ng 9/7, Th·ªß t∆∞·ªõng Nguy·ªÖn Xu√¢n Ph√∫c ch·ªß tr√¨ h...   \n",
       "3  V·ªõi b·ªëi c·∫£nh hi·ªán nay, H·ªôi ƒë·ªìng T∆∞ v·∫•n ch√≠nh s...   \n",
       "4  L·ªùi t√≤a so·∫°n Th·ªã tr∆∞·ªùng b·∫•t ƒë·ªông s·∫£n ng√†y c√†ng...   \n",
       "\n",
       "                                              corpus  \\\n",
       "0  Th·ªß t∆∞·ªõng: Kh√°c v·ªõi ƒëa s·ªë c√°c n∆∞·ªõc, d∆∞ ƒë·ªãa ch√≠...   \n",
       "1  Th·ªëng nh·∫•t k·ªãch b·∫£n tƒÉng tr∆∞·ªüng 3-4%, l·∫°m ph√°t...   \n",
       "2  ƒê·ªÅ xu·∫•t tƒÉng li·ªÅu l∆∞·ª£ng g√≥i k√≠ch th√≠ch kinh t·∫ø...   \n",
       "3  Th·ªß t∆∞·ªõng: Kh√°c v·ªõi ƒëa s·ªë c√°c n∆∞·ªõc, d∆∞ ƒë·ªãa ch√≠...   \n",
       "4  T√°c ƒë·ªông t·ª´ ch√≠nh s√°ch t√≠n d·ª•ng: BƒêS c√≥ th·ªÉ ƒë√≥...   \n",
       "\n",
       "                                        clean_corpus  \n",
       "0  Th·ªß_t∆∞·ªõng Kh√°c v·ªõi ƒëa_s·ªë c√°c n∆∞·ªõc d∆∞ ƒë·ªãa_ch√≠nh...  \n",
       "1  Th·ªëng_nh·∫•t k·ªãch_b·∫£n tƒÉng_tr∆∞·ªüng l·∫°m_ph√°t d∆∞·ªõi ...  \n",
       "2  ƒê·ªÅ_xu·∫•t tƒÉng li·ªÅu_l∆∞·ª£ng g√≥i k√≠ch_th√≠ch kinh_t·∫ø...  \n",
       "3  Th·ªß_t∆∞·ªõng Kh√°c v·ªõi ƒëa_s·ªë c√°c n∆∞·ªõc d∆∞ ƒë·ªãa_ch√≠nh...  \n",
       "4  T√°c_ƒë·ªông t·ª´ ch√≠nh_s√°ch t√≠n_d·ª•ng BƒêS c√≥_th·ªÉ ƒë√≥n...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_corpus'] = df['corpus'].apply(clean_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(876, 6145)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(df['clean_corpus'])\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3b347065-59af-414d-8fee-f37389be5b5d"
   },
   "source": [
    "### Khai ph√° d·ªØ li·ªáu text (Text Mining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It was the best of times',\n",
       " 'It was the worst of times',\n",
       " 'It was the age of wisdom',\n",
       " 'It was the age of foolishness']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\n",
    "    'It was the best of times', # best times\n",
    "    'It was the worst of times', # worst times\n",
    "    'It was the age of wisdom', # age wisdom\n",
    "    'It was the age of foolishness' # age foolishness\n",
    "]\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0b82a86e-d2e8-4c4c-a418-124c90218d1f"
   },
   "source": [
    "#### Kh√°i ni·ªám Bag-of-Words\n",
    "\n",
    "L√† k·ªπ thu·∫≠t chia vƒÉn b·∫£n th√†nh c√°c t·ªï h·ª£p t·ª´ kh√°c nhau (b·∫±ng ph∆∞∆°ng ph√°p tokenize). C√°ch chia ph·ªï bi·∫øn l√† m·ªói c√¢u th√†nh 1 vƒÉn b·∫£n (bag) v√† m·ªói vƒÉn b·∫£n ƒë∆∞·ª£c chia th√†nh t·ª´ (word). D·ª±a v√†o ƒë√≥ c√≥ th·ªÉ ƒëo l∆∞·ªùng m·ª©c ƒë·ªô xu·∫•t hi·ªán c·ªßa c√°c t·ª´ trong vƒÉn b·∫£n v√† x√¢y d·ª±ng m·ªëi li√™n h·ªá gi·ªØa ng·ªØ c·∫£nh v√† c√°c t·ª´. \n",
    "\n",
    "Hai y·∫øu t·ªë:\n",
    "1. T·ª´ ƒëi·ªÉn c·ªßa c√°c t·ª´ ƒë∆∞·ª£c s·ª≠ d·ª•ng\n",
    "2. M·ª©c ƒë·ªô xu·∫•t hi·ªán c·ªßa c√°c t·ª´ trong t·ª´ ƒëi·ªÉn\n",
    "*M·ªói t·ª´ hay token ƒë∆∞·ª£c g·ªçi l√† m·ªôt `gram`*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3645f46c-63e0-4a38-a1f5-ad8ab78b8aa3"
   },
   "source": [
    "#### TF-IDF (Term frequency-Inverse Document frequency)\n",
    "\n",
    "Ng·ªØ c·∫£nh: \"I am very angry\" ==> \"very angry\" # t·∫≠p trung v√†o c√°c t·ª´ mang nhi·ªÅu th√¥ng tin\n",
    "\n",
    "ƒê∆°n v·ªã ƒë·ªÉ ƒëo th√¥ng tin trong khoa h·ªçc machine-learning: entropy\n",
    "\n",
    "ƒêo l∆∞·ªùng t·∫ßn su·∫•t ***h·ª£p l√Ω*** m·ªôt t·ª´ (hay token) xu·∫•t hi·ªán trong vƒÉn b·∫£n. T·∫ßn su·∫•t n√†y ƒë∆∞·ª£c t√≠nh b·∫±ng: M·ª©c ƒë·ªô xu·∫•t hi·ªán c·ªßa t·ª´ trong vƒÉn b·∫£n chia cho t·ªâ l·ªá vƒÉn b·∫£n m√† t·ª´ ƒë√≥ xu·∫•t hi·ªán tr√™n t·ªïng t·∫•t c·∫£ s·ªë l∆∞·ª£ng vƒÉn b·∫£n.\n",
    "\n",
    "V√≠ d·ª•: ƒë·ªëi v·ªõi nh∆∞ `what` hay `the`, c√°c t·ª´ n√†y xu·∫•t hi·ªán r·∫•t nhi·ªÅu tuy nhi√™n ko mang nhi·ªÅu √Ω nghƒ©a n√™n c·∫ßn c√≥ ph∆∞∆°ng ph√°p lo·∫°i tr·ª´ c√°c t·ª´ n√†y ra kh·ªèi m√¥ h√¨nh. V√¨ v·∫≠y ngo√†i t√≠nh to√°n m·ª©c ƒë·ªô xu·∫•t hi·ªán c·ªßa c√°c t·ª´ trong vƒÉn b·∫£n, tuy nhi√™n n·∫øu vƒÉn b·∫£n n√†o c≈©ng xu·∫•t hi·ªán t·ª´ n√†y (ho·∫∑c ƒë∆°n gi·∫£n l√† r·∫•t nhi·ªÅu > 90%) th√¨ c√°c t·ª´ n√†y s·∫Ω b·ªã lo·∫°i ra.\n",
    "\n",
    "$$ tf-idf(t, d, D)  = tf(t, d) \\dot idf(t, D)$$\n",
    "\n",
    "> `t`: t·ª´ (word hay token)\n",
    " \n",
    "> `d`: vƒÉn b·∫£n (document)\n",
    " \n",
    "> `D`: t·ªáp c√°c vƒÉn b·∫£n (documents)\n",
    "\n",
    "trong ƒë√≥:\n",
    "\n",
    "$$ tf(t, d) = \\log(1 + freq(t, d)) $$\n",
    "$$ idf(t, D) = \\log \\left( \\dfrac{N}{count(d \\in D: t \\in d)} \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "30bc2036-7dc6-4b33-baac-7c1ab14fe285"
   },
   "source": [
    "#### M√¥ h√¨nh Word2vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "966f5ac5-3024-4991-8a7b-27ec8002ac29"
   },
   "source": [
    "*\"Word2Vec was developed at Google by Tomas Mikolov, et al. and uses Neural Networks to learn word embeddings. The beauty with word2vec is that the vectors are learned by understanding the context in which words appear. The result is vectors in which words with similar meanings end up with a similar numerical representation.\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dbe00fd3-483f-4343-b331-8bdbde4d8d03"
   },
   "source": [
    "**One-hot-encoding**\n",
    "\n",
    "All word are treated equal\n",
    "\n",
    "![](https://i2.wp.com/insightbot.blob.core.windows.net/blogimagecontainer/b3c56245-db43-48ab-b652-9ba03f4d9900.jpg?ssl=1)\n",
    "\n",
    "**Word2Vec**\n",
    "\n",
    "Word with similar numeric value are similar in meaning\n",
    "\n",
    "![](https://i1.wp.com/insightbot.blob.core.windows.net/blogimagecontainer/8cbfc874-3ba3-46c8-ab68-2711812ecbf1.jpg?ssl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "124e7484-2125-4bfa-8033-9f11341f6c93"
   },
   "source": [
    "Hai lo·∫°i m√¥ h√¨nh Word2Vec: **CBOW** (Continuous Bag-of-Word) v√† **Skip-Gram**\n",
    "\n",
    "Continuous Bag of Words (CBOW): *nh√¨n h√¨nh (ng·ªØ c·∫£nh) ƒëo√°n ch·ªØ*\n",
    "\n",
    "Ng∆∞·ª£c l·∫°i, Skip-Gram: *nh√¨n ch·ªØ ƒëo√°n h√¨nh (ng·ªØ c·∫£nh)*\n",
    "\n",
    "![](https://i0.wp.com/insightbot.blob.core.windows.net/blogimagecontainer/7938152f-71c8-4f28-9c25-06735e6e2b67.jpg?ssl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03aea233-3d03-4566-8876-153325d71cd9"
   },
   "source": [
    "**Skip-gram**\n",
    "\n",
    "Window Size defines how many words before and after the target word will be used as context, typically a Window Size is 5. \n",
    "![](https://i2.wp.com/insightbot.blob.core.windows.net/blogimagecontainer/a8066c1d-c532-4549-bb24-19dfea5eb178_med.jpg?ssl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "860004a0-d665-4d69-a4b6-41f7ef94ccea"
   },
   "source": [
    "Using a window size of 2 the input pairs for training on w(4) royal would be:\n",
    "![](https://israelg99.github.io/images/2017-03-23-Word2Vec-Explained/training_data.png)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "d16c807e-c950-44b4-923a-3da9c08f74e8",
    "eec9ba76-913e-4803-a39b-d6b537ed57bb",
    "a0d782c1-6302-4a8e-b8de-e936565beb95",
    "0b82a86e-d2e8-4c4c-a418-124c90218d1f",
    "3645f46c-63e0-4a38-a1f5-ad8ab78b8aa3",
    "30bc2036-7dc6-4b33-baac-7c1ab14fe285"
   ],
   "name": "nlp.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
