{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5869783-46cd-4ef5-8d80-b1c6eaf559bd"
   },
   "source": [
    "# Xử lý ngôn ngữ tự nhiên và khai phá dữ liệu văn bản\n",
    "\n",
    "![](https://www.thuatngumarketing.com/wp-content/uploads/2017/12/NLP.png.pagespeed.ce_.1YNuw_5dJH.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "372869b4-6785-4aaa-8abc-3e29d875fb0c"
   },
   "source": [
    "## Định nghĩa\n",
    "\n",
    "> **Xử lí ngôn ngữ tự nhiên**: Sử dụng các kỹ thuật phân tích và làm sạch dữ liệu kết hợp với mô hình học máy để khai thác thông tin trong dữ liệu ngôn ngữ.\n",
    "\n",
    "> **Dữ liệu ngôn ngữ**: Nói cho nhau nghe (dữ liệu ngôn ngữ âm thanh) và viết cho nhau đọc (dữ liệu ngôn ngữ văn bản)\n",
    "\n",
    "> **Text Mining**: Kỹ thuật xử lý dữ liệu dạng văn bản và khai thác thông tin từ dữ liệu văn bản.\n",
    "\n",
    "![](https://www.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0108.png)\n",
    "\n",
    "## Ứng dụng\n",
    "\n",
    "![](https://www.oreilly.com/library/view/practical-natural-language/9781492054047/assets/pnlp_0101.png)\n",
    "\n",
    "> Tham khảo: [Practical Natural Language Processing by Sowmya Vajjala, Bodhisattwa Majumder, Anuj Gupta, Harshit Surana\n",
    "](https://www.oreilly.com/library/view/practical-natural-language/9781492054047/ch01.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "da1ff90f-7126-4e50-8272-e7bb5ebc5092"
   },
   "source": [
    "## Quy trình\n",
    "\n",
    "> 1. **Preprocessing** (Tiền xử lý) (Làm sạch & Chuẩn hoá dữ liệu)\n",
    "> 2. **Tokenizing** (Tách từ) -> Dua ve cac cum chung\n",
    "> 3. **Vectorizing** (Vectơ hóa)\n",
    "> 4. **Modeling** (Xây dựng mô hình)\n",
    "> 5. **Intepreting result & Application** (Ứng dụng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4de5b914-9acd-4e9f-9072-a6663fea3313"
   },
   "source": [
    "## Công cụ và thư viện\n",
    "\n",
    "1. Python Nature Language Toolkit ([Python NLTK](https://www.nltk.org/)), PyVi hỗ trợ xử lý dữ liệu dạng văn bản.\n",
    "2. Gensim/Tensorflow/Scikit-learn hỗ trợ xây dựng mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4da8ab72-48f2-4e8d-b889-1f8637c81797"
   },
   "source": [
    "#### 1. Tiền xử lý dữ liệu text (Text preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "651749cb-7a5f-4843-b816-67b5a34effde"
   },
   "source": [
    "#### TODO: Làm sạch dữ liệu chỉ giữ lại dữ liệu bằng chữ\n",
    "1. Nếu là dữ liệu scrapped từ web thì chỉ trích lọc dữ liệu chứ (text only)\n",
    "2. Loại bỏ hyperlink (nếu có) # https://baophapluat.com # lẫn thành từ word \n",
    "3. Nếu là dữ liệu web thì cần loại bỏ emoji # :smile: :angry:\n",
    "4. Loại bỏ tất cả các dấu (.,\\/!@#$%^&*()+_ etc.)\n",
    "```\n",
    "r'[\\,\\.\\/\\\\\\!\\@\\#\\+\\\"\\'\\;\\)\\(\\“\\”\\\\\\-\\:…&><=\\-\\%\\|\\^\\$\\&\\)\\(\\[\\]\\{\\}\\?\\*\\•]'\n",
    "```\n",
    "5. Loại bỏ tất cả các số\n",
    "6. Loại bỏ các khoảng trắng và đổi text thành lowercase # normalize # T == t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mJupyter cannot be started. Error attempting to locate jupyter: Running cells with 'Python 3.8.2 64-bit' requires jupyter and notebook package.\n",
      "Run the following command to install 'jupyter and notebook' into the Python environment. \n",
      "Command: 'conda install -n base jupyter notebook'"
     ]
    }
   ],
   "source": [
    "text = '''<head></head>\n",
    "<body>\n",
    "    <p>\n",
    "    Here's 1 paragraph of text 🔥. !\n",
    "    <a href=\"https://www.dataquest.io\">Learn Data Science Online 🤡</a>\n",
    "    </p>\n",
    "    <p>\n",
    "    Here's a 2nd paragraph of text! Further informations at http://mci.com.vn\n",
    "    <a href=\"https://www.python.org\">Python 101</a> </p>\n",
    "</body></html>'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Tách từ (Tokenization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aa513f1e-0125-4cdc-a268-883af940025b"
   },
   "source": [
    "#### 3. Mã hóa dữ liệu text (Word embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3b347065-59af-414d-8fee-f37389be5b5d"
   },
   "source": [
    "### Khai phá dữ liệu text (Text Mining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It was the best of times',\n",
       " 'It was the worst of times',\n",
       " 'It was the age of wisdom',\n",
       " 'It was the age of foolishness']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\n",
    "    'It was the best of times', # best times\n",
    "    'It was the worst of times', # worst times\n",
    "    'It was the age of wisdom', # age wisdom\n",
    "    'It was the age of foolishness' # age foolishness\n",
    "]\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0b82a86e-d2e8-4c4c-a418-124c90218d1f"
   },
   "source": [
    "#### Khái niệm Bag-of-Words\n",
    "\n",
    "Là kỹ thuật chia văn bản thành các tổ hợp từ khác nhau (bằng phương pháp tokenize). Cách chia phổ biến là mỗi câu thành 1 văn bản (bag) và mỗi văn bản được chia thành từ (word). Dựa vào đó có thể đo lường mức độ xuất hiện của các từ trong văn bản và xây dựng mối liên hệ giữa ngữ cảnh và các từ. \n",
    "\n",
    "Hai yếu tố:\n",
    "1. Từ điển của các từ được sử dụng\n",
    "2. Mức độ xuất hiện của các từ trong từ điển\n",
    "*Mỗi từ hay token được gọi là một `gram`*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3645f46c-63e0-4a38-a1f5-ad8ab78b8aa3"
   },
   "source": [
    "#### TF-IDF (Term frequency-Inverse Document frequency)\n",
    "\n",
    "Ngữ cảnh: \"I am very angry\" ==> \"very angry\" # tập trung vào các từ mang nhiều thông tin\n",
    "\n",
    "Đơn vị để đo thông tin trong khoa học machine-learning: entropy\n",
    "\n",
    "Đo lường tần suất ***hợp lý*** một từ (hay token) xuất hiện trong văn bản. Tần suất này được tính bằng: Mức độ xuất hiện của từ trong văn bản chia cho tỉ lệ văn bản mà từ đó xuất hiện trên tổng tất cả số lượng văn bản.\n",
    "\n",
    "Ví dụ: đối với như `what` hay `the`, các từ này xuất hiện rất nhiều tuy nhiên ko mang nhiều ý nghĩa nên cần có phương pháp loại trừ các từ này ra khỏi mô hình. Vì vậy ngoài tính toán mức độ xuất hiện của các từ trong văn bản, tuy nhiên nếu văn bản nào cũng xuất hiện từ này (hoặc đơn giản là rất nhiều > 90%) thì các từ này sẽ bị loại ra.\n",
    "\n",
    "$$ tf-idf(t, d, D)  = tf(t, d) \\dot idf(t, D)$$\n",
    "\n",
    "> `t`: từ (word hay token)\n",
    " \n",
    "> `d`: văn bản (document)\n",
    " \n",
    "> `D`: tệp các văn bản (documents)\n",
    "\n",
    "trong đó:\n",
    "\n",
    "$$ tf(t, d) = \\log(1 + freq(t, d)) $$\n",
    "$$ idf(t, D) = \\log \\left( \\dfrac{N}{count(d \\in D: t \\in d)} \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "30bc2036-7dc6-4b33-baac-7c1ab14fe285"
   },
   "source": [
    "#### Mô hình Word2vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "966f5ac5-3024-4991-8a7b-27ec8002ac29"
   },
   "source": [
    "*\"Word2Vec was developed at Google by Tomas Mikolov, et al. and uses Neural Networks to learn word embeddings. The beauty with word2vec is that the vectors are learned by understanding the context in which words appear. The result is vectors in which words with similar meanings end up with a similar numerical representation.\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dbe00fd3-483f-4343-b331-8bdbde4d8d03"
   },
   "source": [
    "**One-hot-encoding**\n",
    "\n",
    "All word are treated equal\n",
    "\n",
    "![](https://i2.wp.com/insightbot.blob.core.windows.net/blogimagecontainer/b3c56245-db43-48ab-b652-9ba03f4d9900.jpg?ssl=1)\n",
    "\n",
    "**Word2Vec**\n",
    "\n",
    "Word with similar numeric value are similar in meaning\n",
    "\n",
    "![](https://i1.wp.com/insightbot.blob.core.windows.net/blogimagecontainer/8cbfc874-3ba3-46c8-ab68-2711812ecbf1.jpg?ssl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "124e7484-2125-4bfa-8033-9f11341f6c93"
   },
   "source": [
    "Hai loại mô hình Word2Vec: **CBOW** (Continuous Bag-of-Word) và **Skip-Gram**\n",
    "\n",
    "Continuous Bag of Words (CBOW): *nhìn hình (ngữ cảnh) đoán chữ*\n",
    "\n",
    "Ngược lại, Skip-Gram: *nhìn chữ đoán hình (ngữ cảnh)*\n",
    "\n",
    "![](https://i0.wp.com/insightbot.blob.core.windows.net/blogimagecontainer/7938152f-71c8-4f28-9c25-06735e6e2b67.jpg?ssl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03aea233-3d03-4566-8876-153325d71cd9"
   },
   "source": [
    "**Skip-gram**\n",
    "\n",
    "Window Size defines how many words before and after the target word will be used as context, typically a Window Size is 5. \n",
    "![](https://i2.wp.com/insightbot.blob.core.windows.net/blogimagecontainer/a8066c1d-c532-4549-bb24-19dfea5eb178_med.jpg?ssl=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "860004a0-d665-4d69-a4b6-41f7ef94ccea"
   },
   "source": [
    "Using a window size of 2 the input pairs for training on w(4) royal would be:\n",
    "![](https://israelg99.github.io/images/2017-03-23-Word2Vec-Explained/training_data.png)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "d16c807e-c950-44b4-923a-3da9c08f74e8",
    "eec9ba76-913e-4803-a39b-d6b537ed57bb",
    "a0d782c1-6302-4a8e-b8de-e936565beb95",
    "0b82a86e-d2e8-4c4c-a418-124c90218d1f",
    "3645f46c-63e0-4a38-a1f5-ad8ab78b8aa3",
    "30bc2036-7dc6-4b33-baac-7c1ab14fe285"
   ],
   "name": "nlp.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
